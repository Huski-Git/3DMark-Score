{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Mark - The Optimal build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the world of technology, PCs have been a widely used device for a number of reasons, one of which is used for gaming. PC Gaming has been rapidly increasing over the coming decades due to the versatility of the different builds of a computer. Prices of gaming computers can range from around  £500 all the way up to north of £15,000 and nowadays PCs are being custom built by individuals or are being built by comissioners.\n",
    "\n",
    "Once the PC may be built they may be content with the completed build however, they may come to the realisation that they may not be able to play a particular game ( E.g. Dark Souls 3 ) due to the fact that the CPU/GPU may not be performing as well as they had hoped and therefore they must purchase a brand new component and waste the original component. Things such as GPU's and RAM cards may be re-used and re-sold, but things such as the CPU, Motherboards tend not to be something that people will sell as it is very difficult to remove the CPU from the Motherboard once inserted due to the fact that the pins that connect the two together are very fragile and as soon as one of the pins are damaged/bent , they cannot be used again.\n",
    "\n",
    "Certain PC builds will be run certain games smoothly ( over 60 frames/sec ) and some may not and we are able to have a good idea of whether it does or not by running 3DMark.\n",
    "\n",
    "3DMark is a benchmarking tool that is run on a particular PC and runs a simulation. This simulation primarily takes into account the GPU and the CPU and sees the different kind of intensities they are able to handle with ease. At the end of the simulation, it provides a 3DMark Score where the higher value indicates that it has a higher average performance throughout all different graphic settings.\n",
    "\n",
    "In This capstone project, we will be attempting to predict the 3DMark Score a particular Computer build will have and thus we will be able to have an idea of whether they will be running smoothly or not. \n",
    "\n",
    "We could decide whether we can want to cluster these groups and see if certain builds have similarities and discinction, or we could determine if they will run over 60FPS on average, for all different genres of games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different features of a PC and we will be looking at the components that the  majority of modern custom built PCs will have. The following will not be considered:\n",
    "\n",
    "* Case / Chassis\n",
    "* Floppy Disk Drive\n",
    "* CD-rom Drive\n",
    "* Modem\n",
    "* Sound Card\n",
    "* SSD / HDD\n",
    "\n",
    "The reason for not including some may be due to the fact that they are redundant / have no effect on the actual simulation.\n",
    "\n",
    "Components that are considered :\n",
    "\n",
    "* GPU ( Graphics Processing Unit )\n",
    "* CPU ( Central Processing Unit )\n",
    "* RAM ( Random Access Memory )\n",
    "* Power Supply\n",
    "* Motherboard\n",
    "* Monitor\n",
    "\n",
    "The GPU, CPU and RAM can also vary due to the model type aswell as whether the CPU is able to be overclocked or not. So we will also be looking into the following features aswell:\n",
    "\n",
    "* GPU\n",
    "    * Manufacturer\n",
    "    * \\# Of GPUs ( 1 - 4)\n",
    "    * SLI = True/False\n",
    "    * Clockspeed (MHz)\n",
    "    * VRAM\n",
    "    * VRAM Bandwidth\n",
    "   \n",
    "* CPU\n",
    "    * Base Clockspeed (Mhz)\n",
    "    * Turbo Clockspeed (Mhz)\n",
    "    * MicroArchitechture\n",
    "    * \\# of Cores\n",
    "    * \\# of Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be kindly provided by the company 3DMark,however, while waiting for them to provide the data, I will be scraping some of the data on their website in order to be ready to use my functions well in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: There will be some user_id's where there will not be any results found. This is due to the fact that the user has taken down their results from the website.\n",
    "\n",
    "#### If there is nothing on that user, we will replace with a NaN and then remove them later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "users=[]\n",
    "for iterations in range(3):\n",
    "    user_id = random.randint(10000,10000000)\n",
    "    users.append(user_id)\n",
    "    url= \"https://www.3dmark.com/spy/{}\".format(user_id)\n",
    "    r= requests.get(url)\n",
    "    soup=BeautifulSoup(r.text, 'html.parser')\n",
    "    try:\n",
    "        results.append(soup.find('div',attrs={'class':'result-details mr'}))\n",
    "    except:\n",
    "        results.append(np.nan)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not required\n",
    "def GPU_names(results):\n",
    "    gpu_name=[]\n",
    "    for user in results:\n",
    "        try:\n",
    "            GPU_info = user.find_all('dl',attrs={'class':'data clearfix'})[0]\n",
    "        except:\n",
    "            gpu_name.append(np.nan)\n",
    "        gpu_name.append(GPU_info.find('a',attrs={'class':'hw-link'}).text.strip())\n",
    "    return gpu_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_names(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users=[]\n",
    "for user in range(len(results)):\n",
    "    info=[]\n",
    "    for x in results[user].find_all('dl',attrs={'class':'data clearfix'}):\n",
    "        for i in x.find_all('dd'):\n",
    "            info.append(i.text.strip())\n",
    "    all_users.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_names=[]\n",
    "for x in results[0].find_all('dl',attrs={'class':'data clearfix'}):\n",
    "    for i in x.find_all('dt'):\n",
    "        info_names.append(i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_users=[]\n",
    "for user in all_users:\n",
    "    users=[]\n",
    "    for item in user:\n",
    "        if item not in users:\n",
    "            users.append(item)\n",
    "    new_all_users.append(users)\n",
    "    \n",
    "all_users=new_all_users.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_users[:2],columns=info_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_info_vars=[]\n",
    "for x in GPU_info.find_all('dt'):\n",
    "    GPU_info_vars.append(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_info_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_info_stats=[]\n",
    "for x in GPU_info.find_all('dd'):\n",
    "    GPU_info_stats.append(x.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_info.find_all('dd'):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_results={}\n",
    "CPU_results={}\n",
    "for x in range(len(results)):\n",
    "    GPU_info=results[x].find_all('dl',attrs={'class':'data clearfix'})[0]\n",
    "    CPU_info=results[x].find_all('dl',attrs={'class':'data clearfix'})[1]\n",
    "    \n",
    "    final_results[users[x]['GPU']]={x.text:y.text.strip() for x,y in zip(GPU_info.find_all('dt'),GPU_info.find_all('dd'))}\n",
    "    CPU_results[users[x]]={x.text:y.text.strip() for x,y in zip(CPU_info.find_all('dt'),CPU_info.find_all('dd'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results={x.text:y.text.strip() for x,y in zip(CPU_info.find_all('dt'),CPU_info.find_all('dd'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not required\n",
    "def CPU_names(results):\n",
    "    cpu_name=[]\n",
    "    for user in results:\n",
    "        try:\n",
    "            cpu_info = user.find_all('dl',attrs={'class':'data clearfix'})[1]\n",
    "        except:\n",
    "            cpu_name.append(np.nan)\n",
    "        cpu_name.append(cpu_info.find('a',attrs={'class':'hw-link'}).text.strip())\n",
    "    return cpu_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_names(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_info=results[0].find_all('dl',attrs={'class':'data clearfix'})[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_info=[]\n",
    "for user in results:\n",
    "    CPU_info.append(user.find_all('dl',attrs={\"class\",'data clearifx'})[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_info_vars=[]\n",
    "for x in CPU_info.find_all('dt'):\n",
    "    CPU_info_vars.append(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_info_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_info_stats=[]\n",
    "for x in CPU_info.find_all('dd'):\n",
    "    CPU_info_stats.append(x.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_info_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "boxes = results[1].find_all('dl',{'class':'data clearfix'})\n",
    "dds = boxes[0].find_all('dd')\n",
    "\n",
    "dds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial Runs with just 1 user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url= \"https://www.3dmark.com/spy/10000001\"\n",
    "r=requests.get(url)\n",
    "soup=BeautifulSoup(r.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_info =soup.find_all('dl',attrs={'class':'data clearfix'})[0]\n",
    "CPU_info =soup.find_all('dl',attrs={'class':'data clearfix'})[1]\n",
    "misc_info = soup.find_all('dl',attrs={'class':'data clearfix'})[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GPU_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cpu_name(results):\n",
    "    cpu_name=[]\n",
    "    for user in results:\n",
    "        CPU_info = user.find_all('dl',attrs={'class':'data clearfix'})[1]\n",
    "        try:\n",
    "            cpu_name.append(CPU_info.find('a',attrs={'class':'hw-link'}).text)\n",
    "        except:\n",
    "            cpu_name.append\n",
    "    return cpu_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('dl',attrs={'class':'data clearfix'})[1].find_all('dd')[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find('dl',attrs={'class':'data clearfix'}).findNext(attrs={'class':'data clearfix'}).contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE ACTUAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm import tqdm_notebook\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/Huski/GA_work/DSI11-lessons/projects/project-capstone/3dmark_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GRAPHICS_SCORE','CPU_SCORE'],axis=1).corr()['OVERALL_SCORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['OVERALL_SCORE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to look at : ( suggested by product manager of UL)\n",
    "\n",
    "Verify that with the same CPU, the CPU score scales approximately linearly with the CPU frequency (pick CPUs that support overclocking such as Intel K or X -series to get more data points with different frequencies)  \n",
    "Investigate how memory frequency, memory channels and timings affect the CPU performance - expect it to be different between AMD and Intel and also between different generations and architectures  \n",
    "Investigate how Graphics score scales with changing core & memory clock frequencies with the same GPU\n",
    "Investigate performance differences between different graphics cards and brands and BIOS versions with the same GPU  \n",
    "Check how much score improves with a multi-GPU configuration, is this different between GPUs?  \n",
    "Compare performance of ready-built PCs and DIY PCs with similar components.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning & EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since there are quite a lot of observations where the Overall 3DMark Score are 0, we are going to remove these, since it affects the distribution of it and therefore we will only be looking at the tests in which they were actually successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_types = 'int64'\n",
    "fixed_num = df.select_dtypes(include=numerical_types)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "fixed_num  = pd.DataFrame(scaler.fit_transform(fixed_num),columns=fixed_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Seems that CPU_MAX_CLOCK_SPEED_UNDER_LOAD has a big outlier\n",
    "fig= plt.figure(figsize=(20,20))\n",
    "ax=fig.gca()\n",
    "sns.boxplot(data=fixed_num, orient='h', ax=ax, fliersize=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['OVERALL_SCORE'],fit=norm,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[df['OVERALL_SCORE']!=0]['OVERALL_SCORE'],fit=norm,kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df['OVERALL_SCORE']!=0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# There are some CPU clock speeds in which there are weird errors such as a value like 2,147,483,647\n",
    "# This number is the maximum value for a 32bit signed binary integer in computing.\n",
    "# In order to filter these, we will limit it to 50,000Mhz as the 2014 world-record for high clock speed is\n",
    "# 8,723MHz per Core\n",
    "data=data[data['CPU_MAX_CLOCK_SPEED_UNDER_LOAD']<10000]\n",
    "\n",
    "#We are also going to round the clock speeds to nearest 100Mhz since these are the ideal clock speeds that they\n",
    "# are wanting\n",
    "\n",
    "#data['CPU_MAX_CLOCK_SPEED_UNDER_LOAD']=data['CPU_MAX_CLOCK_SPEED_UNDER_LOAD'].apply(lambda x: round(x,-2))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(data['CPU_MAX_CLOCK_SPEED_UNDER_LOAD'],fit=norm,kde=False,bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CPU_MAX_CLOCK_SPEED_UNDER_LOAD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(data['CPU_MAX_CLOCK_SPEED_UNDER_LOAD'].apply(lambda x: round(x,-2)),fit=norm,kde=False,bins=75);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['CPU_MAX_CLOCK_SPEED_UNDER_LOAD']==5002) | (data['CPU_MAX_CLOCK_SPEED_UNDER_LOAD']==5004)][['CPU_CORES','CPU_THREADS','CPU_SCORE','CPU_NAME']]['CPU_NAME'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CPU_MAX_CLOCK_SPEED_UNDER_LOAD'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since most product names have just a default 'System Product Name', we will convert all the NaN values also to\n",
    "# 'System Product name', as it was probably custom-built by individuals and the individuals will not have bothered\n",
    "# to put the name in.\n",
    "data['SYSTEM_PRODUCT_NAME'].fillna('System Product Name',inplace=True)\n",
    "data['system_version'].fillna('System Version',inplace=True)\n",
    "\n",
    "# For all other columns, we will be dropping all the null values as these will all be strings and we cannot \n",
    "# Determine any of the values for the null values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "#Dropping TIME_SPY_PRESET, since only value is the string 'X' which wont have any effect on the actual \n",
    "data.drop('TIME_SPY_PRESET',axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words_manufacturer(x):\n",
    "    \"\"\"\n",
    "    There are alot of mis-spelled company names that are the same, so we will be cleaning up these company names\n",
    "    \n",
    "    \"\"\"\n",
    "    x=x.lower()\n",
    "    \n",
    "    x=x.replace('co., ltd','')\n",
    "    x=x.replace('.','')\n",
    "    x=x.replace('$','')\n",
    "    x=x.replace(',','')\n",
    "    \n",
    "    x=x.replace('ltd','')\n",
    "    x=x.replace('incorporated','')\n",
    "    x=x.replace('inc','')\n",
    "    x=x.replace('ltt','')\n",
    "    x=x.replace('ldd','')\n",
    "    x=x.replace('x79-16d','')\n",
    "    x=x.replace('limited','')\n",
    "    \n",
    "    x=x.replace('corporation','co')\n",
    "    x=x.replace('corproation','co')\n",
    "    x=x.replace('corportion','co')\n",
    "    x=x.replace('technology and development','')\n",
    "    x=x.replace('corp','')\n",
    "    x=x.replace('innovation and technology','')\n",
    "    x=x.replace('technology','')\n",
    "    x=x.replace('international co','')\n",
    "    x=x.replace('international','')\n",
    "\n",
    "    x=x.replace('asustek computer','asus')\n",
    "    x=x.replace('asrockrack','asrock')\n",
    "    x=x.replace('(shenzen)','')\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    since the string 'co' is in a commpany name called 'colorful' , we cannot change all 'co's to '' as it will\n",
    "    come up with 'lorful'. Same applies for the string 'computer\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    x=x.replace('colorful  co','colorful')\n",
    "    x=x.replace('yu gong  co','')\n",
    "    \n",
    "    x=x.replace('intel co','intel')\n",
    "    x=x.replace('intel oem','intel')\n",
    "    x=x.replace('amd co','amd')\n",
    "    x=x.replace('onda  co','onda')\n",
    "    \n",
    "    x=x.replace('shinelon computer','shinelon')\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    There is a manufacturer called 'huananzhizhi' which causes all sorts of problems due to the fact that the name\n",
    "    has repitition within it.\n",
    "    For example : there is a name called 'huanan' and I need to replace it with 'huananzhizhi'\n",
    "    But if i do this, then the company name called 'huananzhizhi' will be called 'huananzhizhizhizhi'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    x=x.replace('huananzhi','huanan')\n",
    "    x=x.replace('huanan','huananzhi')\n",
    "    \n",
    "    x=x.replace('to be filled by oem','unknown')\n",
    "    x=x.replace('oem','unknown')\n",
    "    return x\n",
    "\n",
    "data['MOTHERBOARD_MANUFACTURER']=data['MOTHERBOARD_MANUFACTURER'].apply(lambda x:replace_words_manufacturer(x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words_system_version(x):\n",
    "    x=x.lower()\n",
    "    x=x.replace('tbd.','tbd')\n",
    "    x=x.replace('tbd by tbd','tbd')\n",
    "    x=x.replace('to be filled by o.e.m.','tbd')\n",
    "    x=x.replace('not applicable','tbd')\n",
    "    x=x.replace('not specified','tbd')\n",
    "    x=x.replace('invalid','tbd')\n",
    "    x=x.replace('oem','tbd')\n",
    "    \n",
    "    return x\n",
    "\n",
    "data['system_version']=data['system_version'].apply(lambda x: replace_words_system_version(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes Processor from the cpu name to prevent it from coming up from CountVectorizer\n",
    "#The actual CPU names is full clean.\n",
    "data['CPU_NAME']=data['CPU_NAME'].apply(lambda x: x.lower().replace('processor',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There seems to be some PCs where they have -1 memory channels which is physically impossible, and we will drop\n",
    "# these\n",
    "data=data[(data['MEMORY_CHANNELS']!=-1) & (data['MEMORY_CHANNELS']!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets get rid of GPU_CORE_CLOCK_SPEED that are 0, This tells us that the BIOS  (Basic Input Output System) is not reading the GPU's speeds\n",
    "# And we are unable to actually determine the actual clock speed.\n",
    "\n",
    "#Upon further research, the reason why most GPU's numbers are reading 0, is because it is using the Integrated Graphics Card\n",
    "#From the CPU rather than the actual GPU itself and so these GPU_SCORES are not from the GPU.\n",
    "data=data[data['GPU_CORE_CLOCK_SPEED']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This seems reasonable as it is possible to have 16,000Mhz of VRAM for a GPU\n",
    "data['GPU_CORE_CLOCK_SPEED'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Getting rid of Memory frequencies of 0 , Suggesting RAM is not being read.\n",
    "data=data[data['MEMORY_FREQUENCY']!=0]\n",
    "data.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets re-check the data and see if there are still any outliers\n",
    "numerical_types = 'int64'\n",
    "fixed_num = data.select_dtypes(include=numerical_types)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "fixed_num  = pd.DataFrame(scaler.fit_transform(fixed_num),columns=fixed_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Main thing to note,  WINDOWS_MAJOR_VERSION & WINDOWS_MINOR_VERSION are int values however since they are a version\n",
    "#They should be considered a string\n",
    "fig= plt.figure(figsize=(20,20))\n",
    "ax=fig.gca()\n",
    "sns.boxplot(data=fixed_num, orient='h', ax=ax, fliersize=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_num  = pd.DataFrame(scaler.fit_transform(fixed_num.drop(['WINDOWS_MAJOR_VERSION','WINDOWS_MINOR_VERSION','WINDOWS_BUILD'],axis=1)),columns=fixed_num.drop(['WINDOWS_MAJOR_VERSION','WINDOWS_MINOR_VERSION','WINDOWS_BUILD'],axis=1).columns)\n",
    "fig= plt.figure(figsize=(20,20))\n",
    "sns.boxplot(data=fixed_num, orient='h', fliersize=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refer to this https://www.techpowerup.com/articles/64\n",
    "#CASLATENCY : The time interval between each bit of information is sent (units in clock cycles)\n",
    "#Not possible to have -1 cycles\n",
    "print(data['CASLATENCY'].unique())\n",
    "data=data[data['CASLATENCY']!=-1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The windows builds doesnt affect the score as mentioned in the technical guide\n",
    "\n",
    "data.drop(['WINDOWS_MAJOR_VERSION','WINDOWS_MINOR_VERSION','WINDOWS_BUILD'],axis=1,inplace=True)\n",
    "data=data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Looking at the top 3 most used CPUs, alot of the time it does seem to be linearly correlated\n",
    "# Reasoning why the same CPU can have different clock speeds and different scores is because it is overclockable\n",
    "# Where the individual is able to choose how hard the CPU will work.\n",
    "sns.lmplot(x='CPU_MAX_CLOCK_SPEED_UNDER_LOAD',y='CPU_SCORE',data=data[data['CPU_NAME']=='intel core i9-9900k '],ci=None)\n",
    "sns.lmplot(x='CPU_MAX_CLOCK_SPEED_UNDER_LOAD',y='CPU_SCORE',data=data[data['CPU_NAME']=='intel core i7-8700k '],ci=None)\n",
    "sns.lmplot(x='CPU_MAX_CLOCK_SPEED_UNDER_LOAD',y='CPU_SCORE',data=data[data['CPU_NAME']=='amd ryzen 7 2700x'],ci=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['CPU_NAME']=='intel core i9-9900k ') & (data['CPU_SCORE']==14347)].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are dropping these because we can directly calculate the OVERALL_SCORE by using the formula provided by\n",
    "# 3DMARK Tehcnical guide : https://s3.amazonaws.com/download-aws.futuremark.com/3dmark-technical-guide.pdf\n",
    "data.drop(['GRAPHICS_SCORE','CPU_SCORE'],axis=1,inplace=True)\n",
    "\n",
    "#Timestamp only tells us when the simulation took place, but does not affect the OVERALL_SCORE\n",
    "data.drop('TIMESTAMP',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['CPU_MAX_CLOCK_SPEED_UNDER_LOAD']<10000][['CPU_MAX_CLOCK_SPEED_UNDER_LOAD','OVERALL_SCORE']].corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df[df['CPU_MAX_CLOCK_SPEED_UNDER_LOAD']<10000]['CPU_MAX_CLOCK_SPEED_UNDER_LOAD'],fit=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining whether GPU is NVIDIA or AMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using this for later during hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = pd.DataFrame(data['GPU_NAME']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphics_card(x):\n",
    "    if 'nvidia' in x.lower():\n",
    "        return 'nvidia'\n",
    "    elif 'amd' in x.lower():\n",
    "        return 'amd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU['NVIDIA/AMD']= GPU['GPU_NAME'].apply(lambda x: graphics_card(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU['NVIDIA/AMD'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COUNT VECTORIZING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will be doing some NLP and therefore will be using the CountVectorizer function to have a look at the number of times a particular word will come up.\n",
    "\n",
    "#### These are the columns we will be count vectorizing:\n",
    "GPU_NAME  \n",
    "GPU_DRIVER_VERSION  \n",
    "GPU_BIOS_VERSION  \n",
    "CPU_NAME  \n",
    "SYSTEM_PRODUCT_NAME  \n",
    "system_version  \n",
    "MOTHER_BOARD_MANUFACTURER  \n",
    "MOTHERBOARD_MODEL   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['GPU_NAME','GPU_DRIVER_VERSION','GPU_BIOS_VERSION',\n",
    "      'CPU_NAME','SYSTEM_PRODUCT_NAME','system_version',\n",
    "      'MOTHERBOARD_MANUFACTURER','MOTHERBOARD_MODEL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=x.apply(lambda y: ' '.join(y), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec= CountVectorizer(stop_words='english',ngram_range=(1,2),max_features=100,token_pattern=r\"(?u)[\\w.-]+|\\w+\")\n",
    "cvec.fit(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=cvec.get_feature_names()\n",
    "cvec_mat = cvec.transform(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count=pd.DataFrame(cvec_mat.sum(axis=0),columns=words).T.sort_values(by=0,ascending=False)\n",
    "word_count.rename(columns={0:'Count'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorised= pd.DataFrame(cvec.transform(all_words).toarray(),columns=words)\n",
    "vectorised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Having a look at the different words. There seem to be individual nuumbers like 7 or 5, this comes from the value\n",
    "#ryzen 5 and ryzen 7 (A particular type of cpu). Since ryzen 7 and ryzen 5 is already in vectorised columns\n",
    "#We will eliminate the '5' and '7' columns and others alike that have no relevence.\n",
    "vectorised.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removed 13 columns\n",
    "vectorised.drop(['wi-fi','7','5','9','filled','filled o.e.m.','tbd asrock','i9-9900k product','i7-8700k product','core','o.e.m. tbd','product','version','gaming','product version'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorised.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all the strings and replacing them as dummifications\n",
    "final_data=pd.concat([data[[col for col in data.columns if col not in x.columns]],vectorised],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#These are the top 10 attributes towards the OVERALL_SCORE , regardless of if it is negative.\n",
    "#From personal knowledge the larget factors seem to be of the GTX 2080 ti that impacts the score greatly.\n",
    "final_data.corr()['OVERALL_SCORE'].sort_values(ascending=False)[:10][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('./huskicapstone.csv',index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNetCV, ElasticNet, LassoCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold , GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark=pd.read_csv('./huskicapstone.csv')\n",
    "X = mark.copy()\n",
    "y = X.pop('OVERALL_SCORE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"350\"\n",
       "            src=\"http://Kis-MacBook-Pro-2.local:40000/dtale/iframe/1\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a287f7f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtale.show(mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)\n",
    "X_test  = pd.DataFrame(scaler.transform(X_test),columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the distribution of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['GPU_COUNT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(X['GPU_COUNT'],fit=norm,bins=50,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.hist(figsize=(24,20),bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power=PowerTransformer()\n",
    "X_trainp=power.fit_transform(X_train)\n",
    "X_testp=power.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_trainp, columns=X_train.columns).hist(figsize=(24,20),bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the Models\n",
    "def save_pickle(element,file):\n",
    "    with open(file, 'wb') as handle:\n",
    "        pickle.dump(element, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#Loading the models\n",
    "def load_pickle(file):\n",
    "    with open(file, 'rb') as handle:\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "#Simple Linear Regression\n",
    "model.fit(X_train,y_train)\n",
    "print('Training Score:',model.score(X_train,y_train))\n",
    "print('Test Score:', model.score(X_test,y_test))\n",
    "\n",
    "#Cross Validating the model\n",
    "scores = cross_val_score(model,X_train,y_train,cv=5)\n",
    "print('Mean Cross Validation Training Score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_pickle(model,'Linear.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pickle('Linear.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = np.linspace(0.01,1,25)\n",
    "model = ElasticNetCV(l1_ratio=ratios,n_alphas=100,cv=5,fit_intercept=True)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "predictions=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_pickle(model,'ElasticNetCV.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_pickle('ElasticNetCV.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_train,model.predict(X_train))**0.5/ y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Alpha:', model.alpha_)\n",
    "print('Best l1_ratio:',model.l1_ratio_)   #Suggests that we will be using Lasso , not Ridge\n",
    "print('Training Score:',model.score(X_train,y_train))\n",
    "print('Test Score:',model.score(X_test,y_test))\n",
    "print(cross_val_score(model,X_train,y_train,cv=5).mean())\n",
    "\n",
    "\n",
    "#These RMSE Scores do not really tell anyone anything unless they know what is included in the data\n",
    "#We know that the mean OVERALL_SCORE is 4944.7, and so that is a 12.3% variability.\n",
    "print('Training data RMSE:', mean_squared_error(y_train,model.predict(X_train))**0.5)\n",
    "print('Test data RMSE:', mean_squared_error(y_test,predictions)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attritbutes for ElasticNetCV\n",
    "\n",
    ".l1_ratio_ : tells you the proportionality between Ridge and Lasso  \n",
    ".coef_     : will tell me the correlation between each feature and the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf= KFold(n_splits =5 ,shuffle = True,random_state =1)\n",
    "model = DecisionTreeRegressor(max_depth=5,random_state=1)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_pickle(model,'DecisionTree.pkl')\n",
    "load_pickle('DecisionTree.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Decision Tree Scoes:\\n')\n",
    "print('Training Score:',model.score(X_train,y_train))\n",
    "print('Test Score:',model.score(X_test,y_test))\n",
    "print('Cross Validation Score:',cross_val_score(model,X_train,y_train,cv=kf,scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearching Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeRegressor(criterion='mse', max_depth=None,\n",
       "                                             max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort=False, random_state=1,\n",
       "                                             splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5],\n",
       "                         'max_features': [1, 5, 10, 25],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "params = {'max_depth':[1,2,3,4,5],\n",
    "          'max_features':[1,5,10,25],\n",
    "          'min_samples_leaf':[1,2,3,4]}\n",
    "\n",
    "gs=GridSearchCV(model,param_grid=params,cv=kf)\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_pickle(gs,'GridSearchDT.pkl')\n",
    "gs=load_pickle('GridSearchDT.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes for Gridsearch:\n",
    "\n",
    "gs.best_estimator_ : if you want to find the best parameters for gridsearch to find the best score for decision tree regression\n",
    "\n",
    "gs.best_score : as expected tells you the best score out of all the possible iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gridsearch Decision Tree Training Score:', gs.score(X_train,y_train))\n",
    "print('Gridsearch Decision Tree Test Score:', gs.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=1)\n",
    "\n",
    "params = {'max_depth':[2,3,4],\n",
    "          'max_features':[1,2,5,10],\n",
    "          'n_estimators': list(np.logspace(0,2,30).astype(int))}\n",
    "\n",
    "gs=GridSearchCV(model,param_grid=params,cv=kf)\n",
    "                        \n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_pickle(gs,'RandomForestGrid.pkl')\n",
    "model=load_pickle('RandomForestGrid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Training Score:',model.best_score_)\n",
    "print('Test Score:',model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=1,\n",
    "                              max_depth=4,\n",
    "                              max_features=10,\n",
    "                              n_estimators=100)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from os import system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree_image(model, filename='tree.png'):\n",
    "    dotfile = open(\"tree.dot\", 'w')\n",
    "    export_graphviz(model.best_estimator_, out_file=dotfile, feature_names=X.columns, filled=True,rounded=True, special_characters=True)\n",
    "    dotfile.close()\n",
    "    # comment out this line if you don't have GraphViz yet\n",
    "    system(\"dot -Tpng tree.dot -o {0}\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_tree_image(model,'tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.best_estimator_.feature_importances_,index=X.columns).sort_values(by=0,ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.best_estimator_.feature_importances_,index=X.columns).sort_values(by=0,ascending=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Score:',gs.score(X_train,y_train))\n",
    "print('Test score:',gs.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf=PolynomialFeatures(degree=2,include_bias=False)\n",
    "X_train_std_pf = pf.fit_transform(X_train_std)\n",
    "X_test_std = pf.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_ratios=np.linspace(0.01,1,25)\n",
    "optimal_enet=ElasticNetCV(l1_ratio=l1_ratios,n_alphas=100,cv=5,verbose=0,tol=0.001)\n",
    "optimal_enet.fit(X_train_std_pf,y_train)\n",
    "#lr.fit(X_train_std_pf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(lr,X_train_std_pf,y_train,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('s3://capstonehuski/huskicapstone.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Unique Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note : If the GPU_NAME, GPU_SUBSYSTEM_VENDOR,GPU_SUBSYSTEM_MODEL & GPU_BIOS_VERSION - This tells us that they are from the same brand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)-data[['GPU_NAME','GPU_SUBSYSTEM_VENDOR','GPU_SUBSYSTEM_MODEL','GPU_BIOS_VERSION']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCR = {'TIMESTAMP'                     :'The time at which the simulation was taken',\n",
    "         'TIME_SPY_PRESET'               :'Letter denoting which Time Spy test it is, X:TimeSpyExtreme',\n",
    "         'OVERALL_SCORE'                 :'3D Mark Score',\n",
    "         'GRAPHICS_SCORE'                :'Score for Graphics Card calculated using the Graphics Test 1 and Graphics Test 2',\n",
    "         'CPU_SCORE'                     :'Score for the CPU. 0 Denotes that the CPU test had failed / crashed ',\n",
    "         'CPU_Name'                      :'CPU name, a K or an X represents whether this CPU is Overclockable or not',\n",
    "         'CPU_MAX_CLOCK_SPEED_UNDER_LOAD':'The maximum clock speed, this may or may not be overclocked, we cannot know unless we know the base clock speed',\n",
    "         'CPU_CORES'                     :'The number of cores',\n",
    "         'CPU_Threads'                   :'Some CPU may be multithreading, and some may be hyperthreading',\n",
    "         'MEMORY_Frequency'              :'The amount of bits being sent per second on one data line (MHz)',\n",
    "         'MEMORY_CHANNELS'               :'The number of memory sticks that were used, generally this will be 1,2 or 4',\n",
    "         'CASLATENCY'                    :'',\n",
    "         'RASTOCASDELAY'                 :'',\n",
    "         'RASPRECHARGE'                  :'',\n",
    "         'TRAS'                          :'',\n",
    "         'COMMANDRATE'                   :'',\n",
    "         'GPU_NAME'                      :'This name will tell us the manufacturer and the Model, however not the branding',\n",
    "         'GPU_COUNT'                     :'The number of GPUs used, most PC\\'s will have 1 or 2 but HEDT (High End Desktop) can have 3 or 4. if 2+ This is called a SLI/Crossfire Configuration depending on the GPU manufacturer'\n",
    "         'GPU_DRIVER_VERSION'            :'The Driver Version',\n",
    "         'GPU_SUBSYSTEM_VENDOR'          :'The Branding of the GPU, Different brands will keep the same infrastructure of the actual ',\n",
    "         'GPU_SUBSYSTEM_MODEL'           :'',\n",
    "         'GPU_BIOS_VERSION'              :'',\n",
    "         'SYSTEM_PRODUCT_NAME'           :'Signifies if the PC was custom built by an individual or was prebuilt by a particular company, E.g. \\'All Stars\\' suggests that it was made by ASUS' \n",
    "         'system_version'                :'',\n",
    "         'MOTHERBOARD_MANUFACTURER'      :'',\n",
    "         'MOTHERBOARD_MODEL'             :'',\n",
    "         'WINDOWS_MAJOR_VERSION'         :'',\n",
    "         'WINDOWS_MINOR_VERSION'         :' '}\n",
    "            \n",
    "         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
